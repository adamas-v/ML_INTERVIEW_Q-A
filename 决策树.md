`决策树的底层逻辑中，是信息论的知识，一个苹果是好苹果还是坏苹果，苹果的类别是一个随机变量，有两个可能的状态（好、坏，一开始两者的概率都是0.5），引入一个新的特征（颜色），颜色本身也是一个随机变量，假设有两种状态（红、青）
，此时如果知道苹果的颜色是红色，则苹果是好苹果的概率会增大（好=0.6，坏=0.4），此时苹果类别的概率分布发生改变，则熵也发生改变（减小）。这就是通过条件熵推导信息增益的过程。知道了颜色之后计算的类别的熵就是条件熵，熵前后的差异就是信息增益`


就上面的例子提出几个问题：
1. 一个决策树二分类问题中有多少个随机变量需要考虑
2. 引入颜色特征之后，类别的概率分布式怎么得到的
3. 信息增益的大小是如何影响树的构建的
